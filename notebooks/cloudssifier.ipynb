{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from icecream import ic\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy, Recall, Precision\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipx run mlflow server --host 127.0.0.1 --port 8080 --backend-store-uri sqlite:///my.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 1fd84faa4c314c11b38846a8bf606dc4 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal_Cloudssifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m ic(run\u001b[38;5;241m.\u001b[39minfo)\n",
      "File \u001b[0;32m~/Repos/cloudssifier/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:344\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    342\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    345\u001b[0m         (\n\u001b[1;32m    346\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[0;31mException\u001b[0m: Run with UUID 1fd84faa4c314c11b38846a8bf606dc4 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:8080/')\n",
    "#mlflow.create_experiment('Total_Cloudssifier')\n",
    "mlflow.set_experiment(\"Total_Cloudssifier\")\n",
    "mlflow.set_experiment_tag(\"version\", \"1.0.0\")\n",
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((128, 128)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train = ImageFolder(\"../data/clouds_train\", transform=train_transforms)\n",
    "dataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(64 * 32 * 32, num_classes)\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "        self.recall = Recall(task=\"multiclass\", num_classes=7)\n",
    "        self.precision = Precision(task=\"multiclass\", num_classes=7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.5395\n",
      "Epoch 2, Loss: 1.4980\n",
      "Epoch 3, Loss: 1.3558\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Recall, Precision, Accuracy\n",
    "\n",
    "accuracy = Accuracy(task='multiclass', num_classes=7, average='macro')\n",
    "precision_per_class = Precision(task=\"multiclass\", num_classes=7, average=None)\n",
    "recall_per_class = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "recall_micro = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "recall_macro = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "recall_weighted = Recall(task=\"multiclass\", num_classes=7, average=\"weighted\")\n",
    "\n",
    "net = Net(num_classes=7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "mlflow.log_param('learning_rate', lr)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over training batches\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        accuracy(preds, labels)\n",
    "        precision_per_class(preds, labels)\n",
    "        recall_per_class(preds, labels)\n",
    "        recall_micro(preds, labels)\n",
    "        recall_macro(preds, labels)\n",
    "        recall_weighted(preds, labels)\n",
    "\n",
    "    accuracy.compute()\n",
    "    precision_per_class.compute()\n",
    "    recall_per_class.compute()\n",
    "    recall_micro.compute()\n",
    "    recall_macro.compute()\n",
    "    recall_weighted.compute()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((128, 128)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_test = ImageFolder(\"../data/clouds_test\", transform=test_transforms)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| precision: tensor(0.6173)\n",
      "ic| recall: tensor(0.5016)\n",
      "ic| precision_per_class: tensor([0.4643, 0.9167, 1.0000, 0.3911, 0.4331, 0.4730, 0.6429])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4643, 0.9167, 1.0000, 0.3911, 0.4331, 0.4730, 0.6429])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_accuracy = Accuracy(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_precision_per_class = Precision(task=\"multiclass\", num_classes=7, average=None)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images.float())\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "        metric_accuracy(preds, labels)\n",
    "        metric_precision_per_class(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "accuracy = metric_accuracy.compute()\n",
    "precision_per_class = metric_precision_per_class.compute()\n",
    "\n",
    "mlflow.log_metric('test_precision', precision)\n",
    "mlflow.log_metric(\"test_recall\", recall)\n",
    "mlflow.log_metric(\"test_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cirriform clouds': 0,\n",
       " 'clear sky': 1,\n",
       " 'cumulonimbus clouds': 2,\n",
       " 'cumulus clouds': 3,\n",
       " 'high cumuliform clouds': 4,\n",
       " 'stratiform clouds': 5,\n",
       " 'stratocumulus clouds': 6}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next:\n",
    "\n",
    "Add comments\n",
    "Add MLFlow\n",
    "Serving the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
